# Machine Learning - EE559 (USC)
This repository contains homework assignments for **EE559: Machine Learning** at **USC**, taught by **Professor Mohammad Reza Rajati**. The assignments cover **supervised and unsupervised learning techniques, probabilistic models, optimization, classification, regression, and deep learning**.

## ðŸ“‚ Homework Assignments

### **ðŸ“Œ Homework 1: k-Nearest Neighbors & Linear Regression**
**Skills:** KNN, weighted regression, linear algebra, biomedical data classification  
- Implemented **k-Nearest Neighbors (KNN) regression** to estimate weight from height.
- Derived and analyzed **linear regression equations** and their relationship to KNN.
- Explored **Hessian matrices and gradient optimization**.
- Developed a **binary classifier** for vertebral column disease (disk hernia, spondylolisthesis) using KNN.
- Evaluated model performance using **confusion matrices, precision, recall, and F1-score**.

### **ðŸ“Œ Homework 2: Linear Regression & Feature Engineering**
**Skills:** Gauss-Markov theorem, multiple regression, polynomial regression, KNN regression  
- Proved the **Gauss-Markov theorem** to show **least squares estimators** are **BLUE**.
- Explored **Singular Value Decomposition (SVD) and minimum norm solutions**.
- Implemented **simple & multiple linear regression** on Combined Cycle Power Plant data.
- Investigated **nonlinear transformations and feature interactions** for regression.
- Compared **KNN regression vs. linear regression** using different distance metrics.

### **ðŸ“Œ Homework 3: NaÃ¯ve Bayes & Bayesian Decision Theory**
**Skills:** Bayesian classification, Gamma & Laplace distributions, NaÃ¯ve Bayes, SMOTE  
- Designed **Bayesian optimal classifiers** for Gamma and Laplace-distributed features.
- Calculated **decision boundaries and classification risks** for discrete and continuous variables.
- Built a **NaÃ¯ve Bayes classifier** for tax evasion prediction using Maximum Likelihood Estimation (MLE).
- Developed a **breast cancer prognosis model** using **SMOTE for class balancing**.
- Evaluated models with **confusion matrices, ROC curves, and AUC scores**.

### **ðŸ“Œ Homework 4: MAP Estimation & Time Series Classification**
**Skills:** Maximum a Posteriori (MAP), Fisher information, SVD, Ridge Regression, Time Series Classification  
- Derived **MAP estimators** for Poisson and Gaussian priors.
- Analyzed **regularized least squares regression** using **Singular Value Decomposition (SVD)**.
- Built a **time series classification model** for human activity recognition using **feature extraction**.
- Computed **bootstrap confidence intervals** for feature distributions.

### **ðŸ“Œ Homework 5: Time Series Classification & Logistic Regression**
**Skills:** Logistic regression, feature selection, cross-validation, class imbalance handling  
- Implemented **binary classification** for human activity recognition.
- Compared **L1-penalized logistic regression with traditional logistic regression**.
- Applied **recursive feature elimination (RFE) and stratified cross-validation** to optimize model performance.

### **ðŸ“Œ Homework 6: Support Vector Machines & Kernel Methods**
**Skills:** Parzen Windows, KNN Density Estimation, SVM, Kernel Methods  
- Applied **Parzen window and k-NN density estimation** to probabilistic classification.
- Designed **nonlinear SVM classifiers** using **polynomial and Gaussian kernels**.
- Implemented **one-vs-all multi-class SVM classification** for Anuran species recognition.

### **ðŸ“Œ Homework 7: Neural Networks & Regression with Deep Learning**
**Skills:** Support Vector Regression (SVR), Multiclass Perceptron, Neural Networks, Metric Learning  
- Derived equations for **Support Vector Regression (SVR)**.
- Trained **single-layer perceptrons** using the **Perceptron update rule**.
- Implemented **neural networks for Parkinsonâ€™s disease monitoring**.
- Used **metric learning with Gaussian kernels** to estimate regression outputs.
- Experimented with **early stopping, cross-validation, and neural network architecture tuning**.

---

## **ðŸ›  Skills Demonstrated**
âœ… **Supervised Learning**: Linear regression, logistic regression, KNN, NaÃ¯ve Bayes, SVM, Neural Networks  
âœ… **Unsupervised Learning**: Feature extraction, density estimation  
âœ… **Mathematical Foundations**: Optimization, probability, statistical inference, SVD, MAP estimation  
âœ… **Programming & Tools**: Python, NumPy, Scikit-Learn, Pandas, Matplotlib, Seaborn  
âœ… **Model Evaluation**: Confusion matrices, AUC-ROC, precision-recall, F1-score, bootstrapping  

This coursework has provided a **strong foundation in machine learning theory and practical implementation**. 

---
ðŸ“Œ **Author:** Niveditha  
ðŸ“Œ **Course:** EE559 - Machine Learning  
ðŸ“Œ **Instructor:** Prof. Mohammad Reza Rajati  
ðŸ“Œ **Institution:** University of Southern California (USC)  
