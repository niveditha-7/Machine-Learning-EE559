{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\AssignmentsUSC\\Homework3\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Download the WPBC data from: https://archive.ics.uci.edu/ml/datasets/\n",
    "Breast+Cancer+Wisconsin+(Prognostic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpbc_data = pd.read_csv(path+'/wpbc.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  1    2      3      4       5       6        7       8       9   ...  \\\n",
      "0  119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.1036  0.1086  ...   \n",
      "1    8423  N   61  17.99  10.38  122.80  1001.0  0.11840  0.2776  0.3001  ...   \n",
      "2  842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.1189  0.1255  ...   \n",
      "3  843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.2839  0.2414  ...   \n",
      "4  843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.1328  0.1980  ...   \n",
      "\n",
      "       25      26      27      28      29      30      31       32   33  34  \n",
      "0  139.70  1436.0  0.1195  0.1926  0.3140  0.1170  0.2677  0.08113  5.0   5  \n",
      "1  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601  0.11890  3.0   2  \n",
      "2  159.10  1949.0  0.1188  0.3449  0.3414  0.2032  0.4334  0.09067  2.5   0  \n",
      "3   98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638  0.17300  2.0   0  \n",
      "4  152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364  0.07678  3.5   0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(wpbc_data.head(5))#to check and verify the structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the First 130 non-recurrent cases and the First 37 recurrent cases as your\n",
    "training set. Add record #197 in the data set to your training set as well. (10\n",
    "pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_recurrent_cases = wpbc_data[wpbc_data[1] == 'N'].head(130)\n",
    "recurrent_cases = wpbc_data[wpbc_data[1] == 'R'].head(37)\n",
    "\n",
    "training_set = pd.concat([non_recurrent_cases, recurrent_cases])\n",
    "additional_record = wpbc_data[wpbc_data[0] == 197]\n",
    "\n",
    "if additional_record.empty or additional_record[0].values[0] not in training_set[0].values: #refered to chatgpt for cleaner code\n",
    "    training_set = pd.concat([training_set, additional_record])\n",
    "training_set.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) There are four instances in your training set that are missing the lymph node\n",
    "feature (denoted as ?). This is not a very severe issue, so replace the missing\n",
    "features with the median of the lymph node feature in your training set. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpbc_data[34] = pd.to_numeric(wpbc_data[34], errors='coerce') # Convert '?' to NaN. If the error argument is passed as coerce , then invalid parsing will be set as NaN\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lymph_node_median = wpbc_data[34].median()\n",
    "print(lymph_node_median)\n",
    "wpbc_data[34].fillna(lymph_node_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Binary Classification Using Naive Bayes' Classifiers\n",
    "i. Solve the problem using a Naive Bayes' classifier.3 Use Gaussian class conditional\n",
    "distributions. Report the confusion matrix, ROC, precision, recall, F1\n",
    "score, and AUC for both the train and test data sets. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1    2      3      4       5       6        7        8        9        10  \\\n",
      "0    N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860  0.07055   \n",
      "1    N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
      "2    N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550  0.08180   \n",
      "3    N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
      "4    R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
      "..  ..  ...    ...    ...     ...     ...      ...      ...      ...      ...   \n",
      "193  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862  0.06367   \n",
      "194  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750  0.06500   \n",
      "195  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583  0.05068   \n",
      "196  R    3  21.42  22.84  145.00  1440.0  0.10700  0.19390  0.23800  0.13180   \n",
      "197  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120  0.04989   \n",
      "\n",
      "     ...      25      26       27      28      29       30      31       32  \\\n",
      "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
      "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
      "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
      "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
      "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
      "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
      "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
      "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
      "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
      "196  ...  198.30  2375.0  0.14980  0.4379  0.5411  0.22150  0.2832  0.08981   \n",
      "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
      "\n",
      "      33   34  \n",
      "0    5.0  5.0  \n",
      "1    3.0  2.0  \n",
      "2    2.5  0.0  \n",
      "3    2.0  0.0  \n",
      "4    3.5  0.0  \n",
      "..   ...  ...  \n",
      "193  6.0  2.0  \n",
      "194  1.5  0.0  \n",
      "195  3.7  0.0  \n",
      "196  3.0  1.0  \n",
      "197  3.5  0.0  \n",
      "\n",
      "[198 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "wpbc_data.drop(columns=[0], inplace=True)#drop patient ID\n",
    "print(wpbc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2      3      4      5       6        7       8       9        10      11  \\\n",
      "0  31  18.02  27.60  117.5  1013.0  0.09489  0.1036  0.1086  0.07055  0.1865   \n",
      "1  61  17.99  10.38  122.8  1001.0  0.11840  0.2776  0.3001  0.14710  0.2419   \n",
      "\n",
      "   ...     25      26      27      28      29      30      31       32   33  \\\n",
      "0  ...  139.7  1436.0  0.1195  0.1926  0.3140  0.1170  0.2677  0.08113  5.0   \n",
      "1  ...  184.6  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601  0.11890  3.0   \n",
      "\n",
      "    34  \n",
      "0  5.0  \n",
      "1  2.0  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "0    0\n",
      "1    0\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "wpbc_data[1] = label_encoder.fit_transform(wpbc_data[1])#following homework 1 tips to encode into labels.\n",
    "X = wpbc_data.drop(columns=[1]) #features variables\n",
    "y = wpbc_data[1] #outcome variable/ target\n",
    "print(X.head(2))\n",
    "print(y.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Confusion Matrix:\n",
      " [[77 27]\n",
      " [12 22]]\n",
      "ROC AUC: 0.7519796380090498\n",
      "Precision: 0.4489795918367347\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.5301204819277109\n",
      "\n",
      "Testing Metrics:\n",
      "Confusion Matrix:\n",
      " [[35 12]\n",
      " [ 7  6]]\n",
      "ROC AUC: 0.690671031096563\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.46153846153846156\n",
      "F1 Score: 0.3870967741935484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_train =clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_scores_train = clf.predict_proba(X_train)[:, 1]\n",
    "y_scores_test = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "roc_auc_train = roc_auc_score(y_train, y_scores_train)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "f1_score_train = f1_score(y_train, y_pred_train)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "roc_auc_test = roc_auc_score(y_test, y_scores_test)\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test)\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_train)\n",
    "print(\"ROC AUC:\", roc_auc_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1 Score:\", f1_score_train)\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_test)\n",
    "print(\"ROC AUC:\", roc_auc_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics before and after SMOTE\n",
    "test_metrics_before_SMOTE = {\n",
    "    \"Confusion Matrix\": \"[[35, 12], [7, 6]]\",\n",
    "    \"ROC AUC\": roc_auc_test,\n",
    "    \"Precision\": precision_test,\n",
    "    \"Recall\": recall_test,\n",
    "    \"F1 Score\": f1_score_test\n",
    "}\n",
    "train_metrics_before_SMOTE = {\n",
    "    \"Confusion Matrix\": \"[[77, 27], [12, 22]]\",\n",
    "    \"ROC AUC\": roc_auc_train,\n",
    "    \"Precision\": precision_train,\n",
    "    \"Recall\": recall_train,\n",
    "    \"F1 Score\": f1_score_train\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. This data set is rather imbalanced. Balance your data set using SMOTE,\n",
    "by downsampling the common class in the training set to 90 instances and\n",
    "upsampling the uncommon class to 90 instances. Use k = 5 nearest neighbors\n",
    "in SMOTE. Remember not to change the balance of the test set. Report the\n",
    "confusion matrix, ROC, precision, recall, F1 score, and AUC for both the\n",
    "train and test data sets. Does SMOTE help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution: Counter({0: 90, 1: 90})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "#ref - https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "over = SMOTE(sampling_strategy={1: 90}, k_neighbors=5, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy={0: 90}, random_state=42)\n",
    "pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
    "X_train_balanced, y_train_balanced = pipeline.fit_resample(X_train, y_train)\n",
    "print(f\"New class distribution: {Counter(y_train_balanced)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      "               2           3           4           5            6   \\\n",
      "count  138.000000  138.000000  138.000000  138.000000   138.000000   \n",
      "mean    45.420290   17.524710   22.431014  115.626522   978.672464   \n",
      "std     34.792778    3.027145    4.466822   20.555917   334.840350   \n",
      "min      1.000000   10.950000   10.380000   71.900000   371.100000   \n",
      "25%     13.000000   15.122500   19.517500   99.422500   716.600000   \n",
      "50%     37.500000   17.495000   21.860000  114.450000   951.550000   \n",
      "75%     69.500000   19.545000   25.217500  129.100000  1186.750000   \n",
      "max    125.000000   25.730000   39.280000  174.200000  2010.000000   \n",
      "\n",
      "               7           8           9           10          11  ...  \\\n",
      "count  138.000000  138.000000  138.000000  138.000000  138.000000  ...   \n",
      "mean     0.102640    0.142777    0.156386    0.087350    0.192936  ...   \n",
      "std      0.012961    0.049634    0.071569    0.033207    0.026629  ...   \n",
      "min      0.078850    0.046050    0.031100    0.020310    0.130800  ...   \n",
      "25%      0.093762    0.111100    0.106850    0.065263    0.176750  ...   \n",
      "50%      0.100900    0.130800    0.144100    0.086340    0.189450  ...   \n",
      "75%      0.109900    0.169425    0.197075    0.101950    0.210300  ...   \n",
      "max      0.144700    0.311400    0.426800    0.201200    0.265500  ...   \n",
      "\n",
      "               25           26          27          28          29  \\\n",
      "count  138.000000   138.000000  138.000000  138.000000  138.000000   \n",
      "mean   140.912899  1402.373188    0.144569    0.361760    0.430415   \n",
      "std     27.200970   527.885157    0.020940    0.151218    0.162367   \n",
      "min     87.220000   514.000000    0.092730    0.097450    0.082010   \n",
      "25%    121.575000   986.500000    0.130900    0.251875    0.324825   \n",
      "50%    139.450000  1296.500000    0.142500    0.344900    0.398600   \n",
      "75%    159.625000  1688.750000    0.153550    0.421950    0.525625   \n",
      "max    229.300000  3234.000000    0.222600    0.932700    1.170000   \n",
      "\n",
      "               30          31          32          33          34  \n",
      "count  138.000000  138.000000  138.000000  138.000000  138.000000  \n",
      "mean     0.180532    0.322702    0.090009    2.734058    2.601449  \n",
      "std      0.042062    0.069525    0.019148    1.879800    4.709890  \n",
      "min      0.065750    0.160300    0.056440    0.400000    0.000000  \n",
      "25%      0.153125    0.280550    0.076930    1.500000    0.000000  \n",
      "50%      0.180000    0.314250    0.086320    2.350000    1.000000  \n",
      "75%      0.206525    0.352550    0.100198    3.500000    2.000000  \n",
      "max      0.275600    0.663800    0.173000   10.000000   27.000000  \n",
      "\n",
      "[8 rows x 33 columns]\n",
      "1\n",
      "0    104\n",
      "1     34\n",
      "Name: count, dtype: int64\n",
      "After SMOTE:\n",
      "               2           3           4           5            6   \\\n",
      "count  208.000000  208.000000  208.000000  208.000000   208.000000   \n",
      "mean    37.341346   17.896903   22.432002  118.157211  1024.939622   \n",
      "std     31.853739    3.231263    4.018638   22.079107   364.496882   \n",
      "min      1.000000   10.950000   10.380000   71.900000   371.100000   \n",
      "25%     12.750000   15.095194   19.592500   98.648319   715.664340   \n",
      "50%     24.500000   18.070000   22.030252  118.700000  1004.000000   \n",
      "75%     56.000000   19.806148   24.679507  131.092490  1223.833266   \n",
      "max    125.000000   25.730000   39.280000  174.200000  2010.000000   \n",
      "\n",
      "               7           8           9           10          11  ...  \\\n",
      "count  208.000000  208.000000  208.000000  208.000000  208.000000  ...   \n",
      "mean     0.102760    0.142961    0.158967    0.090565    0.191211  ...   \n",
      "std      0.011581    0.045312    0.069179    0.034860    0.024045  ...   \n",
      "min      0.078850    0.046050    0.031100    0.020310    0.130800  ...   \n",
      "25%      0.094588    0.113075    0.109525    0.065267    0.177465  ...   \n",
      "50%      0.102391    0.133771    0.152050    0.086980    0.189000  ...   \n",
      "75%      0.108985    0.168125    0.198025    0.109508    0.203980  ...   \n",
      "max      0.144700    0.311400    0.426800    0.201200    0.265500  ...   \n",
      "\n",
      "               25           26          27          28          29  \\\n",
      "count  208.000000   208.000000  208.000000  208.000000  208.000000   \n",
      "mean   145.611383  1496.986554    0.145199    0.366573    0.433448   \n",
      "std     30.391435   603.191516    0.019845    0.139260    0.147090   \n",
      "min     87.220000   514.000000    0.092730    0.097450    0.082010   \n",
      "25%    121.350000  1006.147487    0.132327    0.263587    0.338025   \n",
      "50%    142.400000  1419.000000    0.144115    0.354450    0.409784   \n",
      "75%    162.500000  1816.750000    0.153703    0.422975    0.517450   \n",
      "max    229.300000  3234.000000    0.222600    0.932700    1.170000   \n",
      "\n",
      "               30          31          32          33          34  \n",
      "count  208.000000  208.000000  208.000000  208.000000  208.000000  \n",
      "mean     0.183060    0.321093    0.089677    3.022041    3.618348  \n",
      "std      0.040549    0.063103    0.017643    1.801452    5.237050  \n",
      "min      0.065750    0.160300    0.056440    0.400000    0.000000  \n",
      "25%      0.154079    0.280850    0.077675    1.695448    0.000000  \n",
      "50%      0.181150    0.314197    0.086320    2.798469    1.000000  \n",
      "75%      0.208950    0.345942    0.099306    3.668481    5.281047  \n",
      "max      0.275600    0.663800    0.173000   10.000000   27.000000  \n",
      "\n",
      "[8 rows x 33 columns]\n",
      "1\n",
      "0    104\n",
      "1    104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Before SMOTE:\")\n",
    "print(X_train.describe())\n",
    "print(y_train.value_counts())\n",
    "print(\"After SMOTE:\")\n",
    "print(X_train_balanced.describe())\n",
    "print(y_train_balanced.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier_balanced = GaussianNB()\n",
    "classifier_balanced.fit(X_train_balanced, y_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics (Balanced):\n",
      "Confusion Matrix:\n",
      " [[66 24]\n",
      " [32 58]]\n",
      "ROC AUC: 0.784320987654321\n",
      "Precision: 0.7073170731707317\n",
      "Recall: 0.6444444444444445\n",
      "F1 Score: 0.6744186046511628\n",
      "\n",
      "Testing Metrics (Balanced):\n",
      "Confusion Matrix:\n",
      " [[35 12]\n",
      " [ 6  7]]\n",
      "ROC AUC: 0.7135842880523731\n",
      "Precision: 0.3684210526315789\n",
      "Recall: 0.5384615384615384\n",
      "F1 Score: 0.4375\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_scores, y_pred): #used gpt's help to optimize code by using a function unlike previous step. \n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return conf_matrix, roc_auc, precision, recall, f1\n",
    "\n",
    "\n",
    "y_pred_train_balanced = classifier_balanced.predict(X_train_balanced)\n",
    "y_scores_train_balanced = classifier_balanced.predict_proba(X_train_balanced)[:, 1]\n",
    "metrics_train_balanced = evaluate_model(y_train_balanced, y_scores_train_balanced, y_pred_train_balanced)\n",
    "y_pred_test_balanced = classifier_balanced.predict(X_test)\n",
    "y_scores_test_balanced = classifier_balanced.predict_proba(X_test)[:, 1]\n",
    "metrics_test_balanced = evaluate_model(y_test, y_scores_test_balanced, y_pred_test_balanced)\n",
    "print(\"Training Metrics (Balanced):\")\n",
    "print(\"Confusion Matrix:\\n\", metrics_train_balanced[0])\n",
    "print(\"ROC AUC:\", metrics_train_balanced[1])\n",
    "print(\"Precision:\", metrics_train_balanced[2])\n",
    "print(\"Recall:\", metrics_train_balanced[3])\n",
    "print(\"F1 Score:\", metrics_train_balanced[4])\n",
    "print(\"\\nTesting Metrics (Balanced):\")\n",
    "print(\"Confusion Matrix:\\n\", metrics_test_balanced[0])\n",
    "print(\"ROC AUC:\", metrics_test_balanced[1])\n",
    "print(\"Precision:\", metrics_test_balanced[2])\n",
    "print(\"Recall:\", metrics_test_balanced[3])\n",
    "print(\"F1 Score:\", metrics_test_balanced[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_after_SMOTE = {\n",
    "    \"Confusion Matrix\": \"[[35, 12], [6, 7]]\",\n",
    "    \"ROC AUC\": metrics_test_balanced[1],\n",
    "    \"Precision\": metrics_test_balanced[2],\n",
    "    \"Recall\": metrics_test_balanced[3],\n",
    "    \"F1 Score\": metrics_test_balanced[4]\n",
    "}\n",
    "train_metrics_after_SMOTE = {\n",
    "    \"Confusion Matrix\": \"[[66, 24], [32, 58]]\",\n",
    "    \"ROC AUC\": metrics_train_balanced[1],\n",
    "    \"Precision\": metrics_train_balanced[2],\n",
    "    \"Recall\": metrics_train_balanced[3],\n",
    "    \"F1 Score\": metrics_train_balanced[4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Confusion Matrix   ROC AUC  Precision    Recall  F1 Score\n",
      "Before SMOTE TEST  [[35, 12], [7, 6]]  0.690671   0.333333  0.461538  0.387097\n",
      "After SMOTE TEST   [[35, 12], [6, 7]]  0.713584   0.368421  0.538462  0.437500\n",
      "                        Confusion Matrix   ROC AUC  Precision    Recall  \\\n",
      "Before SMOTE train  [[77, 27], [12, 22]]  0.751980   0.448980  0.647059   \n",
      "After SMOTE train   [[66, 24], [32, 58]]  0.784321   0.707317  0.644444   \n",
      "\n",
      "                    F1 Score  \n",
      "Before SMOTE train  0.530120  \n",
      "After SMOTE train   0.674419  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_before_smote_test = pd.DataFrame(test_metrics_before_SMOTE, index=[\"Before SMOTE TEST\"])\n",
    "df_after_smote_test = pd.DataFrame(test_metrics_after_SMOTE, index=[\"After SMOTE TEST\"])\n",
    "df_before_smote_train = pd.DataFrame(train_metrics_before_SMOTE, index=[\"Before SMOTE train\"])\n",
    "df_after_smote_train = pd.DataFrame(train_metrics_after_SMOTE, index=[\"After SMOTE train\"])\n",
    "\n",
    "comparison_df_test= pd.concat([df_before_smote_test, df_after_smote_test])\n",
    "print(comparison_df_test)\n",
    "comparison_df_train= pd.concat([df_before_smote_train, df_after_smote_train])\n",
    "print(comparison_df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set Analysis\n",
    "ROC AUC: Increased from 0.690671 to 0.713584. This improvement, while not as significant as in the testing set, still shows enhanced model performance.\n",
    "Precision: Improved from 0.333333 to 0.368421, suggesting a moderate increase in the accuracy of positive predictions under test conditions.\n",
    "Recall: Increased from 0.461538 to 0.538462, indicating that the model is now better at identifying all positive cases.\n",
    "F1 Score: Improved from 0.387097 to 0.437500, which reflects a better balance of precision and recall on the testing dataset.\n",
    "\n",
    "\n",
    "Training Set Analysis\n",
    "ROC AUC: Increased from 0.751980 to 0.784321. This indicates an improvement in the model's ability to distinguish between classes.\n",
    "Precision: Improved significantly from 0.448980 to 0.707317, suggesting that the model became more accurate in predicting positive cases.\n",
    "Recall: Decreased slightly from 0.647059 to 0.644444, a negligible change, indicating stable sensitivity.\n",
    "F1 Score: Improved from 0.530120 to 0.674419, indicates a better balance between precision and recall which is a critical factor in evaluating the overall accuracy of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCE:\n",
    "https://stackoverflow.com/questions/34794067/how-to-set-a-cell-to-nan-in-a-pandas-dataframe\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) (Extra practice, will not be graded) Solve the regression problem of estimating\n",
    "time to recurrence (third attribute) using the next 32 attributes. You can use\n",
    "KNN regression. To do it in a principled way, select 20% of data points each class\n",
    "in your training set to choose the best k 2 1; 2; : : : ; 20, and the rest 80% as the\n",
    "new training set. Report your MSE on the test set using the k you found and the\n",
    "whole training set (not only the new training set!). For simplicity, use Euclidean\n",
    "Distance. Repeat this process when you apply SMOTE to your new training set\n",
    "to only upsample the rare class and make the data completely balanced. Does\n",
    "SMOTE help in reducing the MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with k=1 on the whole training set: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the training set for k tuning\n",
    "X_tuning, X_new_train, y_tuning, y_new_train = train_test_split(X_train, y_train, test_size=0.8, random_state=42)\n",
    "\n",
    "# Find the best k\n",
    "errors = []\n",
    "for k in range(1, 21):\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_tuning, y_tuning)\n",
    "    predictions = model.predict(X_tuning)\n",
    "    mse = mean_squared_error(y_tuning, predictions)\n",
    "    errors.append((mse, k))\n",
    "\n",
    "best_k = min(errors)[1]\n",
    "model = KNeighborsRegressor(n_neighbors=best_k)\n",
    "model.fit(X_train, y_train)  # Use the whole training set\n",
    "predictions = model.predict(X_test)\n",
    "mse_full = mean_squared_error(y_test, predictions)\n",
    "print(f\"MSE with k={best_k} on the whole training set: {mse_full}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with SMOTE and k=1: 0.36666666666666664\n",
      "Original MSE: 0.26666666666666666\n",
      "MSE after SMOTE: 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_smoted, y_smoted = smote.fit_resample(X_new_train, y_new_train)\n",
    "\n",
    "# Retrain using the best k on the SMOTEd new training set\n",
    "model.fit(X_smoted, y_smoted)\n",
    "predictions_smote = model.predict(X_test)\n",
    "mse_smote = mean_squared_error(y_test, predictions_smote)\n",
    "print(f\"MSE with SMOTE and k={best_k}: {mse_smote}\")\n",
    "print(f\"Original MSE: {mse_full}\")\n",
    "print(f\"MSE after SMOTE: {mse_smote}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the final test answer reveals that MSE before and after remains same and hence SMOTE here does not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
