{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating total UPDRS with M=5,10,15,. each M is evaluated in separate iteration blocks with their respective result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\AssignmentsUSC\\Homework7\\homework-7-updated-link-niveditha-7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = path+'\\parkinsons_updrs.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject#</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>test_time</th>\n",
       "      <th>motor_UPDRS</th>\n",
       "      <th>total_UPDRS</th>\n",
       "      <th>Jitter(%)</th>\n",
       "      <th>Jitter(Abs)</th>\n",
       "      <th>Jitter:RAP</th>\n",
       "      <th>Jitter:PPQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer(dB)</th>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <th>Shimmer:APQ11</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>28.199</td>\n",
       "      <td>34.398</td>\n",
       "      <td>0.00662</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.00401</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.01438</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>0.01662</td>\n",
       "      <td>0.04314</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>21.640</td>\n",
       "      <td>0.41888</td>\n",
       "      <td>0.54842</td>\n",
       "      <td>0.16006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6660</td>\n",
       "      <td>28.447</td>\n",
       "      <td>34.894</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.01072</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.02982</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>27.183</td>\n",
       "      <td>0.43493</td>\n",
       "      <td>0.56477</td>\n",
       "      <td>0.10810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6810</td>\n",
       "      <td>28.695</td>\n",
       "      <td>35.389</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.00734</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.01458</td>\n",
       "      <td>0.02202</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>23.047</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.54405</td>\n",
       "      <td>0.21014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6470</td>\n",
       "      <td>28.905</td>\n",
       "      <td>35.810</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.01106</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>0.01963</td>\n",
       "      <td>0.03317</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>24.445</td>\n",
       "      <td>0.48730</td>\n",
       "      <td>0.57794</td>\n",
       "      <td>0.33277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6420</td>\n",
       "      <td>29.187</td>\n",
       "      <td>36.375</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.00679</td>\n",
       "      <td>0.00929</td>\n",
       "      <td>0.01819</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>26.126</td>\n",
       "      <td>0.47188</td>\n",
       "      <td>0.56122</td>\n",
       "      <td>0.19361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject#  age  sex  test_time  motor_UPDRS  total_UPDRS  Jitter(%)  \\\n",
       "0         1   72    0     5.6431       28.199       34.398    0.00662   \n",
       "1         1   72    0    12.6660       28.447       34.894    0.00300   \n",
       "2         1   72    0    19.6810       28.695       35.389    0.00481   \n",
       "3         1   72    0    25.6470       28.905       35.810    0.00528   \n",
       "4         1   72    0    33.6420       29.187       36.375    0.00335   \n",
       "\n",
       "   Jitter(Abs)  Jitter:RAP  Jitter:PPQ5  ...  Shimmer(dB)  Shimmer:APQ3  \\\n",
       "0     0.000034     0.00401      0.00317  ...        0.230       0.01438   \n",
       "1     0.000017     0.00132      0.00150  ...        0.179       0.00994   \n",
       "2     0.000025     0.00205      0.00208  ...        0.181       0.00734   \n",
       "3     0.000027     0.00191      0.00264  ...        0.327       0.01106   \n",
       "4     0.000020     0.00093      0.00130  ...        0.176       0.00679   \n",
       "\n",
       "   Shimmer:APQ5  Shimmer:APQ11  Shimmer:DDA       NHR     HNR     RPDE  \\\n",
       "0       0.01309        0.01662      0.04314  0.014290  21.640  0.41888   \n",
       "1       0.01072        0.01689      0.02982  0.011112  27.183  0.43493   \n",
       "2       0.00844        0.01458      0.02202  0.020220  23.047  0.46222   \n",
       "3       0.01265        0.01963      0.03317  0.027837  24.445  0.48730   \n",
       "4       0.00929        0.01819      0.02036  0.011625  26.126  0.47188   \n",
       "\n",
       "       DFA      PPE  \n",
       "0  0.54842  0.16006  \n",
       "1  0.56477  0.10810  \n",
       "2  0.54405  0.21014  \n",
       "3  0.57794  0.33277  \n",
       "4  0.56122  0.19361  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets.\n",
      "Data standardized.\n",
      "X_train_scaled shape: (4112, 19)\n",
      "X_test_scaled shape: (1763, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from metric_learn import MLKR\n",
    "\n",
    "\n",
    "X = df.drop(columns=['motor_UPDRS', 'total_UPDRS', 'subject#'])\n",
    "y_total = df['total_UPDRS']\n",
    "\n",
    "# Split the data into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_total_train, y_total_test = train_test_split(\n",
    "    X, y_total, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\"Data split into training and testing sets.\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data standardized.\")\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_with_mlkr(X_train, y_train, X_test, n_components):\n",
    "    print(f\"Applying MLKR with {n_components} components...\")\n",
    "    mlkr = MLKR(init='auto', n_components=n_components)\n",
    "    mlkr.fit(X_train, y_train)\n",
    "    X_train_mlkr = mlkr.transform(X_train)\n",
    "    X_test_mlkr = mlkr.transform(X_test)\n",
    "    print(f\"MLKR transformation done. X_train_mlkr shape: {X_train_mlkr.shape}, X_test_mlkr shape: {X_test_mlkr.shape}\")\n",
    "    return X_train_mlkr, X_test_mlkr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def tune_krr_hyperparameters(X_train, y_train):\n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    krr = KernelRidge(kernel='rbf')\n",
    "    param_grid = {\n",
    "        'alpha': [0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    grid_search = GridSearchCV(krr, param_grid, cv=5, scoring='r2', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Hyperparameter tuning completed.\")\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best R^2 score: \", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 5 for Total UPDRS\n",
      "\n",
      "Fold 1\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 5), X_test_mlkr shape: (823, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.8289713781067973\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.8682788985275673, R^2 Test: 0.8386162517536062\n",
      "\n",
      "Fold 2\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 5), X_test_mlkr shape: (823, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8583751044551982\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9664941842364294, R^2 Test: 0.8746260096327008\n",
      "\n",
      "Fold 3\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 5), X_test_mlkr shape: (822, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7936495028679061\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.8334997157529961, R^2 Test: 0.7847025354600128\n",
      "\n",
      "Fold 4\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 5), X_test_mlkr shape: (822, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8000825848370763\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9804776067674424, R^2 Test: 0.8092555257445987\n",
      "\n",
      "Fold 5\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 5), X_test_mlkr shape: (822, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8738363763587144\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9641501290467901, R^2 Test: 0.8583525335532287\n",
      "Total UPDRS Results:\n",
      "   R2_test_mean  R2_train_mean\n",
      "5      0.833111        0.92258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_total = {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [5]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Total UPDRS\")\n",
    "    r2_train_scores_total = []\n",
    "    r2_test_scores_total = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train_scaled)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_total, y_val_fold_total = y_total_train.iloc[train_index], y_total_train.iloc[val_index]\n",
    "        \n",
    "        print(f\"Training set size: {X_train_fold.shape[0]}, Validation set size: {X_val_fold.shape[0]}\")\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_total, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_total)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_total)\n",
    "        y_train_pred_total = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_total = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_total = r2_score(y_train_fold_total, y_train_pred_total)\n",
    "        r2_test_total = r2_score(y_val_fold_total, y_val_pred_total)\n",
    "        print(f\"R^2 Train: {r2_train_total}, R^2 Test: {r2_test_total}\")\n",
    "\n",
    "        r2_train_scores_total.append(r2_train_total)\n",
    "        r2_test_scores_total.append(r2_test_total)\n",
    "\n",
    "    results_total[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_total),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_total)\n",
    "    }\n",
    "\n",
    "print(\"Total UPDRS Results:\")\n",
    "total_results_df = pd.DataFrame(results_total).T\n",
    "print(total_results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above best hyper parameter for next iterations to speed up the process: (code remains same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def tune_krr_hyperparameters(X_train, y_train):\n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    krr = KernelRidge(kernel='rbf')\n",
    "    param_grid = {\n",
    "        'alpha': [0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    grid_search = GridSearchCV(krr, param_grid, cv=5, scoring='r2', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Hyperparameter tuning completed.\")\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best R^2 score: \", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 10 for Total UPDRS\n",
      "\n",
      "Fold 1\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 10), X_test_mlkr shape: (823, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7712998707466774\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9829972083096832, R^2 Test: 0.7972693518402463\n",
      "\n",
      "Fold 2\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 10), X_test_mlkr shape: (823, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7357890728447769\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.8071331222652678, R^2 Test: 0.7742831429456805\n",
      "\n",
      "Fold 3\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 10), X_test_mlkr shape: (822, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7739081867989943\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9787496029873015, R^2 Test: 0.8016159352833561\n",
      "\n",
      "Fold 4\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 10), X_test_mlkr shape: (822, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7667965885991296\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9635884707799497, R^2 Test: 0.7863724325166355\n",
      "\n",
      "Fold 5\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 10), X_test_mlkr shape: (822, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.781775564122898\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9700050799192848, R^2 Test: 0.8232821033381795\n",
      "Total UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "10      0.796565       0.940495\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_total = {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [10]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Total UPDRS\")\n",
    "    r2_train_scores_total = []\n",
    "    r2_test_scores_total = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train_scaled)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_total, y_val_fold_total = y_total_train.iloc[train_index], y_total_train.iloc[val_index]\n",
    "        \n",
    "        print(f\"Training set size: {X_train_fold.shape[0]}, Validation set size: {X_val_fold.shape[0]}\")\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_total, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_total)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_total)\n",
    "        y_train_pred_total = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_total = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_total = r2_score(y_train_fold_total, y_train_pred_total)\n",
    "        r2_test_total = r2_score(y_val_fold_total, y_val_pred_total)\n",
    "        print(f\"R^2 Train: {r2_train_total}, R^2 Test: {r2_test_total}\")\n",
    "\n",
    "        r2_train_scores_total.append(r2_train_total)\n",
    "        r2_test_scores_total.append(r2_test_total)\n",
    "\n",
    "    results_total[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_total),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_total)\n",
    "    }\n",
    "\n",
    "print(\"Total UPDRS Results:\")\n",
    "total_results_df = pd.DataFrame(results_total).T\n",
    "print(total_results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "10      0.796565       0.940495\n"
     ]
    }
   ],
   "source": [
    "print(\"Total UPDRS Results:\")\n",
    "total_results_df = pd.DataFrame(results_total).T\n",
    "print(total_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 15 for Total UPDRS\n",
      "\n",
      "Fold 1\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 15), X_test_mlkr shape: (823, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7764440719681757\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9802953920230464, R^2 Test: 0.7894839881732673\n",
      "\n",
      "Fold 2\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 15), X_test_mlkr shape: (823, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7501330764451435\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.8254134017051858, R^2 Test: 0.7863164226477212\n",
      "\n",
      "Fold 3\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 15), X_test_mlkr shape: (822, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7345313803212367\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.7921349595438347, R^2 Test: 0.728857001481003\n",
      "\n",
      "Fold 4\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 15), X_test_mlkr shape: (822, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7390265635509004\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9777975108155552, R^2 Test: 0.7539059203247496\n",
      "\n",
      "Fold 5\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 15), X_test_mlkr shape: (822, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7865320082810636\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9653246094041393, R^2 Test: 0.8126735874831509\n",
      "Total UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "15      0.774247       0.908193\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_total_15= {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [15]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Total UPDRS\")\n",
    "    r2_train_scores_total = []\n",
    "    r2_test_scores_total = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train_scaled)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_total, y_val_fold_total = y_total_train.iloc[train_index], y_total_train.iloc[val_index]\n",
    "        \n",
    "        print(f\"Training set size: {X_train_fold.shape[0]}, Validation set size: {X_val_fold.shape[0]}\")\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_total, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_total)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_total)\n",
    "        y_train_pred_total = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_total = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_total = r2_score(y_train_fold_total, y_train_pred_total)\n",
    "        r2_test_total = r2_score(y_val_fold_total, y_val_pred_total)\n",
    "        print(f\"R^2 Train: {r2_train_total}, R^2 Test: {r2_test_total}\")\n",
    "\n",
    "        r2_train_scores_total.append(r2_train_total)\n",
    "        r2_test_scores_total.append(r2_test_total)\n",
    "\n",
    "    results_total_15[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_total),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_total)\n",
    "    }\n",
    "\n",
    "print(\"Total UPDRS Results:\")\n",
    "total_results_df_15 = pd.DataFrame(results_total_15).T\n",
    "print(total_results_df_15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "15      0.774247       0.908193\n"
     ]
    }
   ],
   "source": [
    "print(\"Total UPDRS Results:\")\n",
    "total_results_df_15 = pd.DataFrame(results_total_15).T\n",
    "print(total_results_df_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For M=p and total UPDRS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 19 for Total UPDRS\n",
      "\n",
      "Fold 1\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 19), X_test_mlkr shape: (823, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7467854241980765\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.807813919831189, R^2 Test: 0.7677421299852951\n",
      "\n",
      "Fold 2\n",
      "Training set size: 3289, Validation set size: 823\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 19), X_test_mlkr shape: (823, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.779050979526171\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.8568396783530042, R^2 Test: 0.8094068419573368\n",
      "\n",
      "Fold 3\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 19), X_test_mlkr shape: (822, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7533830785641806\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.8197000395730938, R^2 Test: 0.7604050743151374\n",
      "\n",
      "Fold 4\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 19), X_test_mlkr shape: (822, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.715870842174887\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9795450504699286, R^2 Test: 0.7339737033949999\n",
      "\n",
      "Fold 5\n",
      "Training set size: 3290, Validation set size: 822\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 19), X_test_mlkr shape: (822, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7844237326061263\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9754085839002512, R^2 Test: 0.820474804613532\n",
      "Total UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "19      0.778401       0.887861\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_total_p= {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [X_train_scaled.shape[1]]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Total UPDRS\")\n",
    "    r2_train_scores_total = []\n",
    "    r2_test_scores_total = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train_scaled)):\n",
    "        print(f\"\\nFold {fold + 1}\")\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_total, y_val_fold_total = y_total_train.iloc[train_index], y_total_train.iloc[val_index]\n",
    "        \n",
    "        print(f\"Training set size: {X_train_fold.shape[0]}, Validation set size: {X_val_fold.shape[0]}\")\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_total, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_total)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_total)\n",
    "        y_train_pred_total = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_total = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_total = r2_score(y_train_fold_total, y_train_pred_total)\n",
    "        r2_test_total = r2_score(y_val_fold_total, y_val_pred_total)\n",
    "        print(f\"R^2 Train: {r2_train_total}, R^2 Test: {r2_test_total}\")\n",
    "\n",
    "        r2_train_scores_total.append(r2_train_total)\n",
    "        r2_test_scores_total.append(r2_test_total)\n",
    "\n",
    "    results_total_p[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_total),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_total)\n",
    "    }\n",
    "\n",
    "print(\"Total UPDRS Results:\")\n",
    "total_results_df_p = pd.DataFrame(results_total_p).T\n",
    "print(total_results_df_p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary for total UPDRS:\n",
    "\n",
    "Total UPDRS Results for M=5:\n",
    "   R2_test_mean  R2_train_mean     0.833111        0.92258\n",
    "\n",
    "Total UPDRS Results for M=10 :\n",
    "    R2_test_mean  R2_train_mean\n",
    "    0.796565       0.940495\n",
    "\n",
    "Total UPDRS Results for M =15:\n",
    "    R2_test_mean = 0.774247 R2_train_mean = 0.908193\n",
    "\n",
    "Total UPDRS Results for M =19:\n",
    "    R2_test_mean = 0.778401   R2_train_mean =         0.887861\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's neural network implementation to train a neural network with two\n",
    "outputs that predicts motor UPDRS and total UPDRS. Use a single layer. You are\n",
    "responsible to determine other architectural parameters of the network, including\n",
    "the number of neurons in the hidden and output layers, method of optimization,\n",
    "type of activation functions, and the L2 \\regularization\" parameter etc. You\n",
    "should determine the design parameters via trial and error, by testing your trained\n",
    "network on the test set and choosing the architecture that yields the smallest test\n",
    "error. For this part, set early-stopping=False. Remember to standardize your\n",
    "features. Report your R2 on both training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference -https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and standardized.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "X = df.drop(columns=['motor_UPDRS', 'total_UPDRS', 'subject#'])\n",
    "y = df[['motor_UPDRS', 'total_UPDRS']]\n",
    "\n",
    "# Split the data into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data split and standardized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6862427648305214, Total UPDRS = 0.6760005168192673\n",
      "R^2 Test: Motor UPDRS = 0.6194099218202306, Total UPDRS = 0.614170250929307\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.6862427648305214, Total UPDRS = 0.6760005168192673\n",
      "R^2 Test: Motor UPDRS = 0.6194099218202306, Total UPDRS = 0.614170250929307\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6860374114451115, Total UPDRS = 0.677966000917251\n",
      "R^2 Test: Motor UPDRS = 0.618158036792386, Total UPDRS = 0.6139382756658163\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.6860374114451115, Total UPDRS = 0.677966000917251\n",
      "R^2 Test: Motor UPDRS = 0.618158036792386, Total UPDRS = 0.6139382756658163\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6888596972035936, Total UPDRS = 0.6805345157303935\n",
      "R^2 Test: Motor UPDRS = 0.6201451287830978, Total UPDRS = 0.6178139163315379\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.6888596972035936, Total UPDRS = 0.6805345157303935\n",
      "R^2 Test: Motor UPDRS = 0.6201451287830978, Total UPDRS = 0.6178139163315379\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6400891183968711, Total UPDRS = 0.6190572591494996\n",
      "R^2 Test: Motor UPDRS = 0.5915097671043792, Total UPDRS = 0.568611047055589\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7123692649388813, Total UPDRS = 0.7071460882164644\n",
      "R^2 Test: Motor UPDRS = 0.6352754960240531, Total UPDRS = 0.6191559438490695\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6437363816570989, Total UPDRS = 0.6175800752854909\n",
      "R^2 Test: Motor UPDRS = 0.5808798940837606, Total UPDRS = 0.5567948036204762\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.734262403597737, Total UPDRS = 0.7301357895431984\n",
      "R^2 Test: Motor UPDRS = 0.6376597187384794, Total UPDRS = 0.6227204410711604\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.656002690055977, Total UPDRS = 0.6380146686185311\n",
      "R^2 Test: Motor UPDRS = 0.5899900116138617, Total UPDRS = 0.5684222778027875\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=relu, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.721866170067563, Total UPDRS = 0.7168826326473079\n",
      "R^2 Test: Motor UPDRS = 0.6270739113562606, Total UPDRS = 0.6096250620543416\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8034571092220958, Total UPDRS = 0.8115599190004368\n",
      "R^2 Test: Motor UPDRS = 0.7151962515368415, Total UPDRS = 0.724356734589592\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8034571092220958, Total UPDRS = 0.8115599190004368\n",
      "R^2 Test: Motor UPDRS = 0.7151962515368415, Total UPDRS = 0.724356734589592\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8034999469190471, Total UPDRS = 0.811586865436906\n",
      "R^2 Test: Motor UPDRS = 0.715162902491443, Total UPDRS = 0.7243845286302917\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8034999469190471, Total UPDRS = 0.811586865436906\n",
      "R^2 Test: Motor UPDRS = 0.715162902491443, Total UPDRS = 0.7243845286302917\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8038258639287558, Total UPDRS = 0.8115945112859048\n",
      "R^2 Test: Motor UPDRS = 0.7147069358787523, Total UPDRS = 0.7241109344280243\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8038258639287558, Total UPDRS = 0.8115945112859048\n",
      "R^2 Test: Motor UPDRS = 0.7147069358787523, Total UPDRS = 0.7241109344280243\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8793067078258423, Total UPDRS = 0.8864039658258834\n",
      "R^2 Test: Motor UPDRS = 0.7782035146182595, Total UPDRS = 0.7769406192561938\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8820009514722742, Total UPDRS = 0.8890924273193913\n",
      "R^2 Test: Motor UPDRS = 0.7786841059220618, Total UPDRS = 0.778607975320647\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8728945526832871, Total UPDRS = 0.8771432783730095\n",
      "R^2 Test: Motor UPDRS = 0.7727366147828546, Total UPDRS = 0.769494874778254\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8781031640446765, Total UPDRS = 0.8837269265875335\n",
      "R^2 Test: Motor UPDRS = 0.7740761167477728, Total UPDRS = 0.7728674350029862\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8733410516525068, Total UPDRS = 0.8797063633583921\n",
      "R^2 Test: Motor UPDRS = 0.7703899220759233, Total UPDRS = 0.7716009152212474\n",
      "\n",
      "Trying hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(50,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8768129953499693, Total UPDRS = 0.8831868488021956\n",
      "R^2 Test: Motor UPDRS = 0.7681920559127059, Total UPDRS = 0.7673071923103363\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7530946862247498, Total UPDRS = 0.745803141455728\n",
      "R^2 Test: Motor UPDRS = 0.6835878149213755, Total UPDRS = 0.6762986491666241\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7530946862247498, Total UPDRS = 0.745803141455728\n",
      "R^2 Test: Motor UPDRS = 0.6835878149213755, Total UPDRS = 0.6762986491666241\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7715207710010976, Total UPDRS = 0.7664733007684132\n",
      "R^2 Test: Motor UPDRS = 0.6966239139855178, Total UPDRS = 0.6903202204603468\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7715207710010976, Total UPDRS = 0.7664733007684132\n",
      "R^2 Test: Motor UPDRS = 0.6966239139855178, Total UPDRS = 0.6903202204603468\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7636564719762687, Total UPDRS = 0.7583607787744031\n",
      "R^2 Test: Motor UPDRS = 0.6914252018610374, Total UPDRS = 0.6846079003474171\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7636564719762687, Total UPDRS = 0.7583607787744031\n",
      "R^2 Test: Motor UPDRS = 0.6914252018610374, Total UPDRS = 0.6846079003474171\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6981740479776604, Total UPDRS = 0.680847476724868\n",
      "R^2 Test: Motor UPDRS = 0.6376539882237984, Total UPDRS = 0.6157795855073975\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7633245482756115, Total UPDRS = 0.7554508512090299\n",
      "R^2 Test: Motor UPDRS = 0.6790486930701785, Total UPDRS = 0.6626557225958464\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.6686332259133634, Total UPDRS = 0.6459665897076781\n",
      "R^2 Test: Motor UPDRS = 0.6076590250905005, Total UPDRS = 0.5869850925424498\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7769043574968505, Total UPDRS = 0.7666136061659796\n",
      "R^2 Test: Motor UPDRS = 0.6808665713210773, Total UPDRS = 0.6640771027447707\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7036610767352982, Total UPDRS = 0.6855816072672896\n",
      "R^2 Test: Motor UPDRS = 0.6332770239343177, Total UPDRS = 0.6061570306529775\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=relu, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7875819344921702, Total UPDRS = 0.7854644629631651\n",
      "R^2 Test: Motor UPDRS = 0.6889913797341083, Total UPDRS = 0.6758115814505175\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=constant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8950951715291279, Total UPDRS = 0.9003990804031566\n",
      "R^2 Test: Motor UPDRS = 0.7699043538187633, Total UPDRS = 0.767971047233466\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=adaptive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8950951715291279, Total UPDRS = 0.9003990804031566\n",
      "R^2 Test: Motor UPDRS = 0.7699043538187633, Total UPDRS = 0.767971047233466\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.001, learning_rate=constant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8950670736981773, Total UPDRS = 0.9003671201339594\n",
      "R^2 Test: Motor UPDRS = 0.7699621204779303, Total UPDRS = 0.768020282130004\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.001, learning_rate=adaptive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8950670736981773, Total UPDRS = 0.9003671201339594\n",
      "R^2 Test: Motor UPDRS = 0.7699621204779303, Total UPDRS = 0.768020282130004\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.01, learning_rate=constant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.894826282256355, Total UPDRS = 0.9000847349016857\n",
      "R^2 Test: Motor UPDRS = 0.7703590055719659, Total UPDRS = 0.7687673473682888\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.01, learning_rate=adaptive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.894826282256355, Total UPDRS = 0.9000847349016857\n",
      "R^2 Test: Motor UPDRS = 0.7703590055719659, Total UPDRS = 0.7687673473682888\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9291567130827659, Total UPDRS = 0.932866332880746\n",
      "R^2 Test: Motor UPDRS = 0.802569281883293, Total UPDRS = 0.795340421093227\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9304067514631081, Total UPDRS = 0.9342066426197014\n",
      "R^2 Test: Motor UPDRS = 0.8043294905694349, Total UPDRS = 0.797879316054841\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9310664568607868, Total UPDRS = 0.935427941977375\n",
      "R^2 Test: Motor UPDRS = 0.7988310180716055, Total UPDRS = 0.7924625850245732\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.93438813925262, Total UPDRS = 0.9383900135333786\n",
      "R^2 Test: Motor UPDRS = 0.802891908788538, Total UPDRS = 0.7970256366652746\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9311339135052427, Total UPDRS = 0.9358369526281116\n",
      "R^2 Test: Motor UPDRS = 0.8107049387252816, Total UPDRS = 0.8020763305096172\n",
      "\n",
      "Trying hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(100,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9339748584147568, Total UPDRS = 0.9384906504390412\n",
      "R^2 Test: Motor UPDRS = 0.8109345230982903, Total UPDRS = 0.8020179737197567\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7922351803551566, Total UPDRS = 0.7851844955602739\n",
      "R^2 Test: Motor UPDRS = 0.7124238186027952, Total UPDRS = 0.7027251341525449\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.7922351803551566, Total UPDRS = 0.7851844955602739\n",
      "R^2 Test: Motor UPDRS = 0.7124238186027952, Total UPDRS = 0.7027251341525449\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8043087855487028, Total UPDRS = 0.7979344806721242\n",
      "R^2 Test: Motor UPDRS = 0.7205734902787966, Total UPDRS = 0.7117168565635847\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8043087855487028, Total UPDRS = 0.7979344806721242\n",
      "R^2 Test: Motor UPDRS = 0.7205734902787966, Total UPDRS = 0.7117168565635847\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.8219261491594196, Total UPDRS = 0.8194648075280978\n",
      "R^2 Test: Motor UPDRS = 0.7235986736506903, Total UPDRS = 0.7177774416931475\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8219261491594196, Total UPDRS = 0.8194648075280978\n",
      "R^2 Test: Motor UPDRS = 0.7235986736506903, Total UPDRS = 0.7177774416931475\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7120363030561188, Total UPDRS = 0.6959165682120039\n",
      "R^2 Test: Motor UPDRS = 0.6534013221505957, Total UPDRS = 0.6394897053022437\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8374593014932202, Total UPDRS = 0.8385180774597026\n",
      "R^2 Test: Motor UPDRS = 0.7148781594945464, Total UPDRS = 0.6986148952676424\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.7476251147347015, Total UPDRS = 0.732295898548518\n",
      "R^2 Test: Motor UPDRS = 0.6859958436776764, Total UPDRS = 0.6671141192578183\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8377613515796579, Total UPDRS = 0.8367426092805272\n",
      "R^2 Test: Motor UPDRS = 0.7310454481273796, Total UPDRS = 0.7142723752388471\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.749178919882942, Total UPDRS = 0.7301520488456674\n",
      "R^2 Test: Motor UPDRS = 0.6826422710831901, Total UPDRS = 0.6554582956956613\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=relu, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.8416057362022236, Total UPDRS = 0.8398738049537893\n",
      "R^2 Test: Motor UPDRS = 0.7188665739744364, Total UPDRS = 0.6945523035510357\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9098522689655743, Total UPDRS = 0.9129144272832936\n",
      "R^2 Test: Motor UPDRS = 0.7656953460168795, Total UPDRS = 0.7680189175482929\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9098522689655743, Total UPDRS = 0.9129144272832936\n",
      "R^2 Test: Motor UPDRS = 0.7656953460168795, Total UPDRS = 0.7680189175482929\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9099428346678905, Total UPDRS = 0.9129509186603623\n",
      "R^2 Test: Motor UPDRS = 0.7653609646492049, Total UPDRS = 0.7675431158508886\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9099428346678905, Total UPDRS = 0.9129509186603623\n",
      "R^2 Test: Motor UPDRS = 0.7653609646492049, Total UPDRS = 0.7675431158508886\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9109269226093648, Total UPDRS = 0.9136768098213311\n",
      "R^2 Test: Motor UPDRS = 0.7660846923624652, Total UPDRS = 0.7673642408695567\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=adam, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9109269226093648, Total UPDRS = 0.9136768098213311\n",
      "R^2 Test: Motor UPDRS = 0.7660846923624652, Total UPDRS = 0.7673642408695567\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9578000398539066, Total UPDRS = 0.9623731162339342\n",
      "R^2 Test: Motor UPDRS = 0.828641611195734, Total UPDRS = 0.8333030605703803\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.0001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9591406468502042, Total UPDRS = 0.9641425652712361\n",
      "R^2 Test: Motor UPDRS = 0.8291818986632997, Total UPDRS = 0.8349969044457973\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.9577868875905672, Total UPDRS = 0.9623643577473306\n",
      "R^2 Test: Motor UPDRS = 0.8287209774937956, Total UPDRS = 0.833231312406556\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.001, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9591315893397606, Total UPDRS = 0.9641449844842476\n",
      "R^2 Test: Motor UPDRS = 0.8292075924024248, Total UPDRS = 0.8348681095343709\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=constant\n",
      "R^2 Train: Motor UPDRS = 0.957736821463774, Total UPDRS = 0.9625580599136779\n",
      "R^2 Test: Motor UPDRS = 0.8297633632611936, Total UPDRS = 0.8327873367298588\n",
      "\n",
      "Trying hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "Neural network trained with hidden_layer_sizes=(200,), activation=tanh, solver=sgd, alpha=0.01, learning_rate=adaptive\n",
      "R^2 Train: Motor UPDRS = 0.9591035035622965, Total UPDRS = 0.9642878542861151\n",
      "R^2 Test: Motor UPDRS = 0.8296763311153432, Total UPDRS = 0.8336368917792583\n",
      "Best parameters: {'hidden_layer_sizes': (200,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0001, 'learning_rate': 'adaptive'}\n",
      "Best R^2 Test: 0.8320894015545486\n",
      "Trial and Error Results:\n",
      "   hidden_layer_sizes activation solver   alpha learning_rate  R2_train_motor  \\\n",
      "0               (50,)       relu   adam  0.0001      constant        0.686243   \n",
      "1               (50,)       relu   adam  0.0001      adaptive        0.686243   \n",
      "2               (50,)       relu   adam  0.0010      constant        0.686037   \n",
      "3               (50,)       relu   adam  0.0010      adaptive        0.686037   \n",
      "4               (50,)       relu   adam  0.0100      constant        0.688860   \n",
      "..                ...        ...    ...     ...           ...             ...   \n",
      "67             (200,)       tanh    sgd  0.0001      adaptive        0.959141   \n",
      "68             (200,)       tanh    sgd  0.0010      constant        0.957787   \n",
      "69             (200,)       tanh    sgd  0.0010      adaptive        0.959132   \n",
      "70             (200,)       tanh    sgd  0.0100      constant        0.957737   \n",
      "71             (200,)       tanh    sgd  0.0100      adaptive        0.959104   \n",
      "\n",
      "    R2_train_total  R2_test_motor  R2_test_total  \n",
      "0         0.676001       0.619410       0.614170  \n",
      "1         0.676001       0.619410       0.614170  \n",
      "2         0.677966       0.618158       0.613938  \n",
      "3         0.677966       0.618158       0.613938  \n",
      "4         0.680535       0.620145       0.617814  \n",
      "..             ...            ...            ...  \n",
      "67        0.964143       0.829182       0.834997  \n",
      "68        0.962364       0.828721       0.833231  \n",
      "69        0.964145       0.829208       0.834868  \n",
      "70        0.962558       0.829763       0.832787  \n",
      "71        0.964288       0.829676       0.833637  \n",
      "\n",
      "[72 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def train_evaluate_nn(X_train, y_train, X_test, y_test, hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, learning_rate='constant'):\n",
    "    model = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        solver=solver,\n",
    "        alpha=alpha,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iter=2000,\n",
    "        early_stopping=False,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Neural network trained with hidden_layer_sizes={hidden_layer_sizes}, activation={activation}, solver={solver}, alpha={alpha}, learning_rate={learning_rate}\")\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    r2_train = r2_score(y_train, y_train_pred, multioutput='raw_values')\n",
    "    r2_test = r2_score(y_test, y_test_pred, multioutput='raw_values')\n",
    "    \n",
    "    print(f\"R^2 Train: Motor UPDRS = {r2_train[0]}, Total UPDRS = {r2_train[1]}\")\n",
    "    print(f\"R^2 Test: Motor UPDRS = {r2_test[0]}, Total UPDRS = {r2_test[1]}\")\n",
    "    \n",
    "    return r2_train, r2_test\n",
    "\n",
    "# Hyperparameter values to try\n",
    "hidden_layer_sizes = [(50,), (100,), (200,)]\n",
    "activations = ['relu', 'tanh']\n",
    "solvers = ['adam', 'sgd']\n",
    "alphas = [0.0001, 0.001, 0.01]\n",
    "learning_rates = ['constant', 'adaptive']\n",
    "\n",
    "best_r2_test = -np.inf\n",
    "best_params = {}\n",
    "results = []\n",
    "\n",
    "# Perform trial and error\n",
    "for hls in hidden_layer_sizes:\n",
    "    for act in activations:\n",
    "        for sol in solvers:\n",
    "            for alpha in alphas:\n",
    "                for lr in learning_rates:\n",
    "                    print(f\"\\nTrying hidden_layer_sizes={hls}, activation={act}, solver={sol}, alpha={alpha}, learning_rate={lr}\")\n",
    "                    r2_train, r2_test = train_evaluate_nn(X_train_scaled, y_train, X_test_scaled, y_test, hidden_layer_sizes=hls, activation=act, solver=sol, alpha=alpha, learning_rate=lr)\n",
    "                    results.append({\n",
    "                        'hidden_layer_sizes': hls,\n",
    "                        'activation': act,\n",
    "                        'solver': sol,\n",
    "                        'alpha': alpha,\n",
    "                        'learning_rate': lr,\n",
    "                        'R2_train_motor': r2_train[0],\n",
    "                        'R2_train_total': r2_train[1],\n",
    "                        'R2_test_motor': r2_test[0],\n",
    "                        'R2_test_total': r2_test[1]\n",
    "                    })\n",
    "                    if r2_test.mean() > best_r2_test:\n",
    "                        best_r2_test = r2_test.mean()\n",
    "                        best_params = {'hidden_layer_sizes': hls, 'activation': act, 'solver': sol, 'alpha': alpha, 'learning_rate': lr}\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best R^2 Test: {best_r2_test}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Trial and Error Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial and Error Results:\n",
      "   hidden_layer_sizes activation solver   alpha learning_rate  R2_train_motor  \\\n",
      "0               (50,)       relu   adam  0.0001      constant        0.686243   \n",
      "1               (50,)       relu   adam  0.0001      adaptive        0.686243   \n",
      "2               (50,)       relu   adam  0.0010      constant        0.686037   \n",
      "3               (50,)       relu   adam  0.0010      adaptive        0.686037   \n",
      "4               (50,)       relu   adam  0.0100      constant        0.688860   \n",
      "..                ...        ...    ...     ...           ...             ...   \n",
      "67             (200,)       tanh    sgd  0.0001      adaptive        0.959141   \n",
      "68             (200,)       tanh    sgd  0.0010      constant        0.957787   \n",
      "69             (200,)       tanh    sgd  0.0010      adaptive        0.959132   \n",
      "70             (200,)       tanh    sgd  0.0100      constant        0.957737   \n",
      "71             (200,)       tanh    sgd  0.0100      adaptive        0.959104   \n",
      "\n",
      "    R2_train_total  R2_test_motor  R2_test_total  \n",
      "0         0.676001       0.619410       0.614170  \n",
      "1         0.676001       0.619410       0.614170  \n",
      "2         0.677966       0.618158       0.613938  \n",
      "3         0.677966       0.618158       0.613938  \n",
      "4         0.680535       0.620145       0.617814  \n",
      "..             ...            ...            ...  \n",
      "67        0.964143       0.829182       0.834997  \n",
      "68        0.962364       0.828721       0.833231  \n",
      "69        0.964145       0.829208       0.834868  \n",
      "70        0.962558       0.829763       0.832787  \n",
      "71        0.964288       0.829676       0.833637  \n",
      "\n",
      "[72 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Trial and Error Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Motor UPDRS:\n",
      "   hidden_layer_sizes activation solver  alpha learning_rate  R2_train_motor  \\\n",
      "70             (200,)       tanh    sgd   0.01      constant        0.957737   \n",
      "\n",
      "    R2_train_total  R2_test_motor  R2_test_total  \n",
      "70        0.962558       0.829763       0.832787  \n",
      "\n",
      "Best parameters for Total UPDRS:\n",
      "   hidden_layer_sizes activation solver   alpha learning_rate  R2_train_motor  \\\n",
      "67             (200,)       tanh    sgd  0.0001      adaptive        0.959141   \n",
      "\n",
      "    R2_train_total  R2_test_motor  R2_test_total  \n",
      "67        0.964143       0.829182       0.834997  \n"
     ]
    }
   ],
   "source": [
    "# Sort by R2_test_motor to find the best model for Motor UPDRS\n",
    "best_motor = results_df.sort_values(by='R2_test_motor', ascending=False).head(1)\n",
    "\n",
    "# Sort by R2_test_total to find the best model for Total UPDRS\n",
    "best_total = results_df.sort_values(by='R2_test_total', ascending=False).head(1)\n",
    "\n",
    "print(\"Best parameters for Motor UPDRS:\")\n",
    "print(best_motor)\n",
    "\n",
    "print(\"\\nBest parameters for Total UPDRS:\")\n",
    "print(best_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping is a technique used to avoid overfitting during training by monitoring the model's performance on a validation set. When the performance on the validation set starts to degrade, training is halted. This helps to find the optimal number of training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Motor UPDRS trained with early stopping.\n",
      "Model with Early Stopping R^2 Train (Motor UPDRS): 0.7861298431253056\n",
      "Model with Early Stopping R^2 Test (Motor UPDRS): 0.7294694956844381\n",
      "Model for Total UPDRS trained with early stopping.\n",
      "Model with Early Stopping R^2 Train (Total UPDRS): 0.7633195857633778\n",
      "Model with Early Stopping R^2 Test (Total UPDRS): 0.7019196432712744\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found previously for Motor UPDRS\n",
    "best_params_motor = {'hidden_layer_sizes': (200,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.01, 'learning_rate': 'constant'}\n",
    "\n",
    "# Train the model with early stopping for Motor UPDRS\n",
    "model_motor = MLPRegressor(\n",
    "    hidden_layer_sizes=best_params_motor['hidden_layer_sizes'],\n",
    "    activation=best_params_motor['activation'],\n",
    "    solver=best_params_motor['solver'],\n",
    "    alpha=best_params_motor['alpha'],\n",
    "    learning_rate=best_params_motor['learning_rate'],\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_motor.fit(X_train_scaled, y_train['motor_UPDRS'])\n",
    "print(\"Model for Motor UPDRS trained with early stopping.\")\n",
    "\n",
    "# Predictions for Motor UPDRS\n",
    "y_train_pred_motor = model_motor.predict(X_train_scaled)\n",
    "y_test_pred_motor = model_motor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model for Motor UPDRS\n",
    "r2_train_motor = r2_score(y_train['motor_UPDRS'], y_train_pred_motor)\n",
    "r2_test_motor = r2_score(y_test['motor_UPDRS'], y_test_pred_motor)\n",
    "\n",
    "print(f\"Model with Early Stopping R^2 Train (Motor UPDRS): {r2_train_motor}\")\n",
    "print(f\"Model with Early Stopping R^2 Test (Motor UPDRS): {r2_test_motor}\")\n",
    "\n",
    "# Best parameters found previously for Total UPDRS\n",
    "best_params_total = {'hidden_layer_sizes': (200,), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0001, 'learning_rate': 'adaptive'}\n",
    "\n",
    "# Train the model with early stopping for Total UPDRS\n",
    "model_total = MLPRegressor(\n",
    "    hidden_layer_sizes=best_params_total['hidden_layer_sizes'],\n",
    "    activation=best_params_total['activation'],\n",
    "    solver=best_params_total['solver'],\n",
    "    alpha=best_params_total['alpha'],\n",
    "    learning_rate=best_params_total['learning_rate'],\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_total.fit(X_train_scaled, y_train['total_UPDRS'])\n",
    "print(\"Model for Total UPDRS trained with early stopping.\")\n",
    "\n",
    "# Predictions for Total UPDRS\n",
    "y_train_pred_total = model_total.predict(X_train_scaled)\n",
    "y_test_pred_total = model_total.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model for Total UPDRS\n",
    "r2_train_total = r2_score(y_train['total_UPDRS'], y_train_pred_total)\n",
    "r2_test_total = r2_score(y_test['total_UPDRS'], y_test_pred_total)\n",
    "\n",
    "print(f\"Model with Early Stopping R^2 Train (Total UPDRS): {r2_train_total}\")\n",
    "print(f\"Model with Early Stopping R^2 Test (Total UPDRS): {r2_test_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing with previous network (early stop = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motor UPDRS:\n",
    "\n",
    "Without early stopping, the model achieves a high R^2 score on both training and test sets, indicating it fits the training data very well and generalizes reasonably to the test data.\n",
    "With early stopping, the R^2 scores are lower on both training and test sets, suggesting that the model did not overfit to the training data, but also did not generalize as well as in the previous case.\n",
    "Total UPDRS:\n",
    "\n",
    "Similar to Motor UPDRS, the model without early stopping achieves higher R^2 scores on both training and test sets compared to the model with early stopping.\n",
    "The decrease in R^2 scores with early stopping indicates that while the model was prevented from overfitting, it did not perform as well on the test data as the non-early-stopping model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
