{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\AssignmentsUSC\\Homework7\\homework-7-updated-link-niveditha-7\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = path+'\\parkinsons_updrs.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject#</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>test_time</th>\n",
       "      <th>motor_UPDRS</th>\n",
       "      <th>total_UPDRS</th>\n",
       "      <th>Jitter(%)</th>\n",
       "      <th>Jitter(Abs)</th>\n",
       "      <th>Jitter:RAP</th>\n",
       "      <th>Jitter:PPQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer(dB)</th>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <th>Shimmer:APQ11</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>28.199</td>\n",
       "      <td>34.398</td>\n",
       "      <td>0.00662</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.00401</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.01438</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>0.01662</td>\n",
       "      <td>0.04314</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>21.640</td>\n",
       "      <td>0.41888</td>\n",
       "      <td>0.54842</td>\n",
       "      <td>0.16006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6660</td>\n",
       "      <td>28.447</td>\n",
       "      <td>34.894</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.01072</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.02982</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>27.183</td>\n",
       "      <td>0.43493</td>\n",
       "      <td>0.56477</td>\n",
       "      <td>0.10810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6810</td>\n",
       "      <td>28.695</td>\n",
       "      <td>35.389</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.00734</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.01458</td>\n",
       "      <td>0.02202</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>23.047</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.54405</td>\n",
       "      <td>0.21014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6470</td>\n",
       "      <td>28.905</td>\n",
       "      <td>35.810</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.01106</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>0.01963</td>\n",
       "      <td>0.03317</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>24.445</td>\n",
       "      <td>0.48730</td>\n",
       "      <td>0.57794</td>\n",
       "      <td>0.33277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6420</td>\n",
       "      <td>29.187</td>\n",
       "      <td>36.375</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.00679</td>\n",
       "      <td>0.00929</td>\n",
       "      <td>0.01819</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>26.126</td>\n",
       "      <td>0.47188</td>\n",
       "      <td>0.56122</td>\n",
       "      <td>0.19361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject#  age  sex  test_time  motor_UPDRS  total_UPDRS  Jitter(%)  \\\n",
       "0         1   72    0     5.6431       28.199       34.398    0.00662   \n",
       "1         1   72    0    12.6660       28.447       34.894    0.00300   \n",
       "2         1   72    0    19.6810       28.695       35.389    0.00481   \n",
       "3         1   72    0    25.6470       28.905       35.810    0.00528   \n",
       "4         1   72    0    33.6420       29.187       36.375    0.00335   \n",
       "\n",
       "   Jitter(Abs)  Jitter:RAP  Jitter:PPQ5  ...  Shimmer(dB)  Shimmer:APQ3  \\\n",
       "0     0.000034     0.00401      0.00317  ...        0.230       0.01438   \n",
       "1     0.000017     0.00132      0.00150  ...        0.179       0.00994   \n",
       "2     0.000025     0.00205      0.00208  ...        0.181       0.00734   \n",
       "3     0.000027     0.00191      0.00264  ...        0.327       0.01106   \n",
       "4     0.000020     0.00093      0.00130  ...        0.176       0.00679   \n",
       "\n",
       "   Shimmer:APQ5  Shimmer:APQ11  Shimmer:DDA       NHR     HNR     RPDE  \\\n",
       "0       0.01309        0.01662      0.04314  0.014290  21.640  0.41888   \n",
       "1       0.01072        0.01689      0.02982  0.011112  27.183  0.43493   \n",
       "2       0.00844        0.01458      0.02202  0.020220  23.047  0.46222   \n",
       "3       0.01265        0.01963      0.03317  0.027837  24.445  0.48730   \n",
       "4       0.00929        0.01819      0.02036  0.011625  26.126  0.47188   \n",
       "\n",
       "       DFA      PPE  \n",
       "0  0.54842  0.16006  \n",
       "1  0.56477  0.10810  \n",
       "2  0.54405  0.21014  \n",
       "3  0.57794  0.33277  \n",
       "4  0.56122  0.19361  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use metric learning with Gaussian kernels1 to estimate each of the outputs mo-\n",
    "tor UPDRS and total UPDRS from the features. As metric learning uses a\n",
    "low dimensional transformation of the features except the non-predictive feature\n",
    "subject#, use 5-fold cross-validation to decide the number of components form\n",
    "M = 5; 10; 15; p, where p is the number of all predictive features you can use.\n",
    "Initialize the linear transformation with PCA features for M = 5; 10; 15 and with\n",
    "original features for M = p. This corresponds to setting init as (default=`auto').\n",
    "Remember to standardize your features. Report the R2 on training and test sets\n",
    "for each of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4112, 19), (1763, 19), (4112,), (1763,), (4112,), (1763,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['motor_UPDRS', 'total_UPDRS', 'subject#'])\n",
    "y_motor = df['motor_UPDRS']\n",
    "y_total = df['total_UPDRS']\n",
    "\n",
    "# Split the data into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_motor_train, y_motor_test, y_total_train, y_total_test = train_test_split(\n",
    "    X, y_motor, y_total, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "X_train.shape, X_test.shape, y_motor_train.shape, y_motor_test.shape, y_total_train.shape, y_total_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarising the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from metric_learn import MLKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and standardized.\n",
      "X_train_scaled shape: (4112, 19)\n",
      "X_test_scaled shape: (1763, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data split and standardized.\")\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_with_mlkr(X_train, y_train, X_test, n_components):\n",
    "    print(f\"Applying MLKR with {n_components} components...\")\n",
    "    mlkr = MLKR(init='auto', n_components=n_components)\n",
    "    mlkr.fit(X_train, y_train)\n",
    "    X_train_mlkr = mlkr.transform(X_train)\n",
    "    X_test_mlkr = mlkr.transform(X_test)\n",
    "    print(f\"MLKR transformation done. X_train_mlkr shape: {X_train_mlkr.shape}, X_test_mlkr shape: {X_test_mlkr.shape}\")\n",
    "    return X_train_mlkr, X_test_mlkr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using hyper parameter tuning to select good parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def tune_krr_hyperparameters(X_train, y_train):\n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    krr = KernelRidge(kernel='rbf')\n",
    "    param_grid = {\n",
    "        'alpha': [0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    grid_search = GridSearchCV(krr, param_grid, cv=5, scoring='r2', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Hyperparameter tuning completed.\")\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best R^2 score: \", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 5 for Motor UPDRS\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 5), X_test_mlkr shape: (823, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8935964223646339\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.938970616403634, R^2 Test: 0.9125729832925135\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 5), X_test_mlkr shape: (823, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8520449866523533\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9842397523130741, R^2 Test: 0.8769130637152367\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 5), X_test_mlkr shape: (822, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8598373829456161\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9786655084055629, R^2 Test: 0.907809571667368\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 5), X_test_mlkr shape: (822, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.9021873121411614\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.962579953777979, R^2 Test: 0.9141183012171689\n",
      "Applying MLKR with 5 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 5), X_test_mlkr shape: (822, 5)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8921711343246926\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.950202123645179, R^2 Test: 0.8792952927577079\n",
      "Motor UPDRS Results:\n",
      "   R2_test_mean  R2_train_mean\n",
      "5      0.898142       0.962932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_motor = {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [5]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Motor UPDRS\")\n",
    "    r2_train_scores_motor = []\n",
    "    r2_test_scores_motor = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_motor, y_val_fold_motor = y_motor_train.iloc[train_index], y_motor_train.iloc[val_index]\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_motor, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_motor)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_motor)\n",
    "        y_train_pred_motor = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_motor = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_motor = r2_score(y_train_fold_motor, y_train_pred_motor)\n",
    "        r2_test_motor = r2_score(y_val_fold_motor, y_val_pred_motor)\n",
    "        print(f\"R^2 Train: {r2_train_motor}, R^2 Test: {r2_test_motor}\")\n",
    "\n",
    "        r2_train_scores_motor.append(r2_train_motor)\n",
    "        r2_test_scores_motor.append(r2_test_motor)\n",
    "\n",
    "    results_motor[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_motor),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_motor)\n",
    "    }\n",
    "\n",
    "print(\"Motor UPDRS Results:\")\n",
    "motor_results_df = pd.DataFrame(results_motor).T\n",
    "print(motor_results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor UPDRS Results for M = 5:\n",
      "Best Hyperparameters: alpha = 0.1, gamma = 0.01\n",
      "Training R^2 Mean: 0.962931590909086\n",
      "Test R^2 Mean: 0.8981418425299991\n"
     ]
    }
   ],
   "source": [
    "print(\"Motor UPDRS Results for M = 5:\")\n",
    "print(f\"Best Hyperparameters: alpha = 0.1, gamma = 0.01\")\n",
    "print(f\"Training R^2 Mean: {results_motor[5]['R2_train_mean']}\")\n",
    "print(f\"Test R^2 Mean: {results_motor[5]['R2_test_mean']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above best hyper parameter for next iterations to speed up the process: (code remains same) (although there might exist another best pparameter if we  do grid search again. but here I am using the above result to manage the training since for M=5, it took me around 138m :may be my system is too slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the GridSearchCV is used with 3-fold cross-validation to find the best hyperparameters (alpha and gamma) for the KernelRidge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def tune_krr_hyperparameters(X_train, y_train):\n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    krr = KernelRidge(kernel='rbf')\n",
    "    param_grid = {\n",
    "        'alpha': [0.1, 1],\n",
    "        'gamma': [0.001, 0.01]\n",
    "    }\n",
    "    grid_search = GridSearchCV(krr, param_grid, cv=3, scoring='r2', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Hyperparameter tuning completed.\")\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best R^2 score: \", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 10 for Motor UPDRS\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 10), X_test_mlkr shape: (823, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8378954275339665\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9775052589664038, R^2 Test: 0.882805394161335\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 10), X_test_mlkr shape: (823, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7328313425072418\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.793392174436814, R^2 Test: 0.7660482864635347\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 10), X_test_mlkr shape: (822, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7985334206661957\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9676262775970077, R^2 Test: 0.8593565435444692\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 10), X_test_mlkr shape: (822, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7954575186887861\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9646123411725895, R^2 Test: 0.8235633829934194\n",
      "Applying MLKR with 10 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 10), X_test_mlkr shape: (822, 10)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7482225300908482\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9732218203732035, R^2 Test: 0.8053211579489661\n",
      "Motor UPDRS Results:\n",
      "   R2_test_mean  R2_train_mean\n",
      "5      0.898142       0.962932\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_motor_10 = {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [10]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Motor UPDRS\")\n",
    "    r2_train_scores_motor = []\n",
    "    r2_test_scores_motor = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_motor, y_val_fold_motor = y_motor_train.iloc[train_index], y_motor_train.iloc[val_index]\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_motor, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_motor)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_motor)\n",
    "        y_train_pred_motor = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_motor = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_motor = r2_score(y_train_fold_motor, y_train_pred_motor)\n",
    "        r2_test_motor = r2_score(y_val_fold_motor, y_val_pred_motor)\n",
    "        print(f\"R^2 Train: {r2_train_motor}, R^2 Test: {r2_test_motor}\")\n",
    "\n",
    "        r2_train_scores_motor.append(r2_train_motor)\n",
    "        r2_test_scores_motor.append(r2_test_motor)\n",
    "\n",
    "    results_motor_10[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_motor),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_motor)\n",
    "    }\n",
    "\n",
    "print(\"Motor UPDRS Results:\")\n",
    "motor_results_df_10 = pd.DataFrame(results_motor_10).T\n",
    "print(motor_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_test_mean  R2_train_mean\n",
      "10      0.827419       0.935272\n"
     ]
    }
   ],
   "source": [
    "print(motor_results_df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor UPDRS Results for M = 10:\n",
      "Best Hyperparameters: alpha = 0.1, gamma = 0.01\n",
      "Training R^2 Mean: 0.9352715745092037\n",
      "Test R^2 Mean: 0.8274189530223449\n"
     ]
    }
   ],
   "source": [
    "print(\"Motor UPDRS Results for M = 10:\")\n",
    "print(f\"Best Hyperparameters: alpha = 0.1, gamma = 0.01\")\n",
    "print(f\"Training R^2 Mean: {results_motor_10[10]['R2_train_mean']}\")\n",
    "print(f\"Test R^2 Mean: {results_motor_10[10]['R2_test_mean']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 15 for Motor UPDRS\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 15), X_test_mlkr shape: (823, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7569070080673557\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9783752821311673, R^2 Test: 0.8247954967483349\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 15), X_test_mlkr shape: (823, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7250140726024039\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.7856022057825135, R^2 Test: 0.7583620418850703\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 15), X_test_mlkr shape: (822, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7882900152402154\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9696961553131573, R^2 Test: 0.8547387902605684\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 15), X_test_mlkr shape: (822, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8184996965497374\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9579007224730429, R^2 Test: 0.8346378420804295\n",
      "Applying MLKR with 15 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 15), X_test_mlkr shape: (822, 15)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.8286934148857567\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9619027269674525, R^2 Test: 0.8557816482455524\n",
      "Motor UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "15      0.825663       0.930695\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_motor_15 = {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [15]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Motor UPDRS\")\n",
    "    r2_train_scores_motor = []\n",
    "    r2_test_scores_motor = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_motor, y_val_fold_motor = y_motor_train.iloc[train_index], y_motor_train.iloc[val_index]\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_motor, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_motor)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_motor)\n",
    "        y_train_pred_motor = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_motor = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_motor = r2_score(y_train_fold_motor, y_train_pred_motor)\n",
    "        r2_test_motor = r2_score(y_val_fold_motor, y_val_pred_motor)\n",
    "        print(f\"R^2 Train: {r2_train_motor}, R^2 Test: {r2_test_motor}\")\n",
    "\n",
    "        r2_train_scores_motor.append(r2_train_motor)\n",
    "        r2_test_scores_motor.append(r2_test_motor)\n",
    "\n",
    "    results_motor_15[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_motor),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_motor)\n",
    "    }\n",
    "\n",
    "print(\"Motor UPDRS Results:\")\n",
    "motor_results_df_15 = pd.DataFrame(results_motor_15).T\n",
    "print(motor_results_df_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "15      0.825663       0.930695\n"
     ]
    }
   ],
   "source": [
    "print(\"Motor UPDRS Results:\")\n",
    "motor_results_df_15 = pd.DataFrame(results_motor_15).T\n",
    "print(motor_results_df_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For M=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating number of components: 19 for Motor UPDRS\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 19), X_test_mlkr shape: (823, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7774142225318021\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9756972535068644, R^2 Test: 0.8310766604455956\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3289, 19), X_test_mlkr shape: (823, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.001}\n",
      "Best R^2 score:  0.7166290617474212\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.7774299816827235, R^2 Test: 0.7478702322424204\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 19), X_test_mlkr shape: (822, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.779674843566638\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9529667491611699, R^2 Test: 0.8341037218957383\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 19), X_test_mlkr shape: (822, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.780132853993245\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9685764723404259, R^2 Test: 0.8026358587401907\n",
      "Applying MLKR with 19 components...\n",
      "MLKR transformation done. X_train_mlkr shape: (3290, 19), X_test_mlkr shape: (822, 19)\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Hyperparameter tuning completed.\n",
      "Best parameters found:  {'alpha': 0.1, 'gamma': 0.01}\n",
      "Best R^2 score:  0.7740733199058649\n",
      "Training the model...\n",
      "Model training and prediction completed.\n",
      "R^2 Train: 0.9674714677174756, R^2 Test: 0.8126150529250654\n",
      "Motor UPDRS Results:\n",
      "    R2_test_mean  R2_train_mean\n",
      "19       0.80566       0.928428\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_motor_p = {}\n",
    "\n",
    "# Evaluate for different values of M\n",
    "for M in [X_train_scaled.shape[1]]:\n",
    "    print(f\"\\nEvaluating number of components: {M} for Motor UPDRS\")\n",
    "    r2_train_scores_motor = []\n",
    "    r2_test_scores_motor = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_scaled):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "        y_train_fold_motor, y_val_fold_motor = y_motor_train.iloc[train_index], y_motor_train.iloc[val_index]\n",
    "\n",
    "        # Transform with MLKR\n",
    "        X_train_fold_mlkr, X_val_fold_mlkr = transform_with_mlkr(X_train_fold, y_train_fold_motor, X_val_fold, n_components=M)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_krr = tune_krr_hyperparameters(X_train_fold_mlkr, y_train_fold_motor)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        print(\"Training the model...\")\n",
    "        best_krr.fit(X_train_fold_mlkr, y_train_fold_motor)\n",
    "        y_train_pred_motor = best_krr.predict(X_train_fold_mlkr)\n",
    "        y_val_pred_motor = best_krr.predict(X_val_fold_mlkr)\n",
    "        print(\"Model training and prediction completed.\")\n",
    "\n",
    "        r2_train_motor = r2_score(y_train_fold_motor, y_train_pred_motor)\n",
    "        r2_test_motor = r2_score(y_val_fold_motor, y_val_pred_motor)\n",
    "        print(f\"R^2 Train: {r2_train_motor}, R^2 Test: {r2_test_motor}\")\n",
    "\n",
    "        r2_train_scores_motor.append(r2_train_motor)\n",
    "        r2_test_scores_motor.append(r2_test_motor)\n",
    "\n",
    "    results_motor_p[M] = {\n",
    "        'R2_train_mean': np.mean(r2_train_scores_motor),\n",
    "        'R2_test_mean': np.mean(r2_test_scores_motor)\n",
    "    }\n",
    "\n",
    "print(\"Motor UPDRS Results:\")\n",
    "motor_results_df_p = pd.DataFrame(results_motor_p).T\n",
    "print(motor_results_df_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary for Motor UPDRS:\n",
    "\n",
    "\n",
    "Motor UPDRS Results for M = 5:\n",
    "Best Hyperparameters: alpha = 0.1, gamma = 0.01\n",
    "Training R^2 Mean: 0.962931590909086\n",
    "Test R^2 Mean: 0.8981418425299991\n",
    "\n",
    "Motor UPDRS Results for M = 10:\n",
    "Best Hyperparameters: alpha = 0.1, gamma = 0.01\n",
    "Training R^2 Mean: 0.9352715745092037\n",
    "Test R^2 Mean: 0.8274189530223449\n",
    "\n",
    "Motor UPDRS Results for M= 15:\n",
    "    R2_test_mean =0.825663   R2_train_mean =0.930695\n",
    "            \n",
    "\n",
    "Motor UPDRS Results for M=p(19): \n",
    "    R2_test_mean =   0.80566   R2_train_mean =0.928428\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
